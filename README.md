# Federated Learning for Ransomware Detection using Language Models

This project provides a robust and modular framework for detecting ransomware activity by analyzing system logs. It leverages Federated Learning (FL) to train Language Models in a privacy-preserving manner and utilizes Parameter-Efficient Fine-Tuning (PEFT) with LoRA to ensure computational and communication efficiency.

## Core Concepts

The methodology is built on a simple yet powerful premise: a Language Model trained exclusively on **normal** system behavior will become highly adept at predicting normal log sequences. When confronted with logs generated by **anomalous** ransomware activity (e.g., rapid file encryption, shadow copy deletion), the model's prediction accuracy will drop significantly. This drop in accuracy serves as a strong signal for anomaly detection.

This framework combines three key concepts:

1.  **Anomaly Detection as Next-Token Prediction**: We treat log analysis as a language modeling task. The model's inability to accurately predict the next log entry in a sequence is our primary indicator of an anomaly.
2.  **Federated Learning (FL)**: To protect the privacy of sensitive system logs, data never leaves the client device. Instead, multiple clients train a global model collaboratively. They only share lightweight model updates (adapters), not their raw data, with a central server for aggregation.
3.  **Efficient Fine-Tuning (LoRA)**: To make training large models feasible on edge devices and to minimize communication costs, we use Low-Rank Adaptation (LoRA). Instead of fine-tuning all model parameters (billions), we only train a tiny fraction of "adapter" parameters, drastically reducing the computational and communication overhead.

---

## Project Structure

The project is organized into a modular structure to separate concerns and improve maintainability.

```
/FL-RANSON-LLM/
├───configs/
│   └───config.yaml         # Central configuration for all experiments
│
├───data/
│   └───ransomlog/
│       ├───raw/            # Place your raw dataset files here
│       └───processed/      # Stores train.csv, test.csv, and tokenized data
│
├───src/
│   ├───data_processing/    # Handles data loading, sessionizing, and tokenization
│   ├───federated_learning/ # Contains the logic for the FL server and clients
│   ├───evaluation/         # Manages model evaluation and metric calculation
│   └───models/             # Handles model initialization and loading
│
├──��main.py                 # Main entrypoint to run the entire pipeline
├───requirements.txt        # Project dependencies
└───README.md               # This file
```

---

## Setup and Installation

Follow these steps to set up the environment.

1.  **Clone the Repository**
    ```bash
    git clone <your-repo-url>
    cd FL-RANSON-LLM
    ```

2.  **Create a Virtual Environment**
    It is highly recommended to use a virtual environment to manage dependencies.
    ```bash
    python -m venv venv
    ```

3.  **Activate the Environment**
    *   On macOS and Linux:
        ```bash
        source venv/bin/activate
        ```
    *   On Windows:
        ```bash
        .\venv\Scripts\activate
        ```

4.  **Install Dependencies**
    First, create the `requirements.txt` file, then install from it.
    ```bash

    # Install the dependencies
    pip install -r requirements.txt
    ```

---

## How to Run the Project

Running an experiment involves three main stages, all orchestrated by the `main.py` script.

### Step 1: Prepare Your Data

1.  Place your raw RansomLog dataset files into the `data/ransomlog/raw/` directory.
2.  **Implement the data processing logic.** This is the most critical user-specific step. Open `src/data_processing/ransomlog_processor.py` and fill in the `TODO` sections:
    *   In the `create_sessions` method, write the Python code to read your raw logs and transform them into `train.csv` and `test.csv` files.
    *   In the `preprocess_and_sanitize` method, define the regular expressions needed to clean and generalize your specific log formats.

### Step 2: Configure Your Experiment

Open `configs/config.yaml` and review the parameters. Adjust them to fit your experiment. Key parameters include:

| Parameter | Description |
| :--- | :--- |
| `simulation_name` | A unique name for your experiment. Results will be saved here. |
| `dataset_name` | The name of the dataset to use (must match a processor). |
| `model_name` | The Hugging Face model to use (e.g., "HuggingFaceTB/SmolLM-135M"). |
| `lora`, `lora_rank` | Whether to use LoRA and the rank of the adapter matrices. |
| `num_rounds` | The total number of federated learning rounds. |
| `num_clients` | The total number of clients in the simulation. |
| `client_frac` | The fraction of clients to participate in each round. |
| `max_steps` | The number of training steps each client performs locally. |

### Step 3: Run the Pipeline

Once your data is in place and your configuration is set, run the main script from the project's root directory:

```bash
python main.py --config configs/config.yaml
```

The script will automatically:
1.  Process your data (if not already processed).
2.  Initialize the global model.
3.  Run the federated training loop for the specified number of rounds.
4.  Evaluate the global model from each round and save the final metrics.

Results, including trained models for each round and final F1 scores, will be saved in the `results/<simulation_name>/` directory.

---

## Extending with a New Dataset

The modular structure makes it easy to add a new dataset processor.

1.  Create a new file, e.g., `src/data_processing/my_dataset_processor.py`.
2.  Implement a new class (e.g., `MyDatasetProcessor`) that inherits from `BaseProcessor`.
3.  Implement the `create_sessions`, `preprocess_and_sanitize`, and `tokenize_dataset` methods with the logic specific to your new dataset.
4.  Update `main.py` to recognize your new dataset by adding an `elif` condition.
```python
# In main.py
elif config['dataset_name'] == 'my_dataset':
    processor = MyDatasetProcessor(config)
```
