# configs/config_edge_ransomware.yaml

# --- General Experiment Settings ---
simulation_name: "EdgeRansomware_SmolLM135M_FedProx"
dataset_name: "edge_ransomware"
description: "FedProx experiment with CIC-BCCC-NRC-Edge-IIoTSet-2022 using SmolLM-135M, LoRA rank 16, and FedProx mu=0.01."

# --- Paths ---
data_base_path: "./data/ids_ransomware/"
results_path: "./results/"

# --- Data Processing Settings ---
session_window_spliter: " ;-; "
force_reprocess_data: True
benign_train_fraction: 0.8     # Split: train uses only benign; test = benign holdout + all ransomware

# --- Model Settings ---
model_name: "HuggingFaceTB/SmolLM-135M"
lora: True
lora_rank: 16                # Optimized: 16 balances performance and communication cost
lora_alpha_multiplier: 2     # alpha = 32 (2x rank)
lora_dropout: 0.1

# --- Federated Learning Settings ---
# HPC Mode: Parallel training enabled (Dual GPU).
use_parallel_training: true
num_rounds: 40
num_clients: 50
client_frac: 0.3

# Data distribution and client behavior
#   data_distribution_strategy: 'iid', 'quantity_skew_dirichlet', 'hetero_device', or 'by_src_ip'
data_distribution_strategy: "hetero_device"
non_iid_alpha: 0.5          # Used only for 'quantity_skew_dirichlet'

# Client selection and aggregation
client_selection_strategy: "data_size_proportional"  # or 'uniform'
use_weighted_aggregation: true

# FedProx regularization (reduces client drift in Non-IID scenarios)
# Set fedprox_mu > 0 to enable. Recommended values: 0.001, 0.01, 0.1
# Reference: https://arxiv.org/abs/1812.06127
fedprox_mu: 0.01

# --- Client Training Settings ---
# Optimized for RTX 4090: Small physical batch + Gradient Accumulation = Large effective batch.
max_steps: 50                # Reduced from 75 to prevent overfitting per round
batch_size: 4
gradient_accumulation_steps: 32
initial_lr: 0.0005
min_lr: 0.00001
lr_scheduler_type: 'cosine'

# --- Evaluation Settings ---
top_k_values: [1, 3, 5, 10]
f1_threshold_steps: 1000

# Enable temporal / early-stage evaluation metrics (TTD, FPR, coverage)
enable_temporal_metrics: true

# --- Decision / Thresholding (operational vs oracle) ---
# threshold_selection:
#   - "f1_max": escolhe limiar maximizando F1 no teste (usa rótulos; bom para comparação, ruim operacionalmente)
#   - "fpr_target": calibra limiar em benigno para atingir um FPR-alvo (não usa rótulos de ataque)
threshold_selection: "f1_max"
fpr_target: 0.01
calibration_source: "train_benign"     # "train_benign" or "test_benign"
calibration_num_samples: 2000

# --- Temporal aggregation (windowed evaluation) ---
# temporal_eval_mode:
#   - "flow": cada fluxo é uma amostra (padrão atual)
#   - "window": agrega fluxos por janela temporal por dispositivo (Src IP)
temporal_eval_mode: "flow"
temporal_window_seconds: 30
temporal_window_agg: "mean"            # "mean", "min", "p10", "p25"

# --- Inference benchmark (deployability) ---
benchmark_inference: false
benchmark_rounds: [0, 40]
benchmark_num_samples: 200
benchmark_warmup: 10

# Evaluation behavior
#  - evaluator_version: "old", "new" ou "both" (quais avaliadores rodar)
#  - accuracy_method: "original" (igual evaluator_antigo) ou "shifted" (LM canônico)
evaluator_version: "both"
accuracy_method: "shifted"
