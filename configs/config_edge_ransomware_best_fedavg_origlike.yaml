# configs/config_edge_ransomware_best_fedavg_origlike.yaml
#
# Full experiment config aligned with the best-performing "origlike" regime:
# - Raw key/value-ish flow representation (default)
# - FedAvg (fedprox_mu = 0)
# - LoRA rank 32, alpha = 4*r
# - LR = 3e-4, client_frac = 0.2, rounds = 30

# --- General Experiment Settings ---
simulation_name: "EdgeRansomware_SmolLM135M_LoRA_R32_LR3e4_Frac0.2_R30_FedAvg_Orig"
dataset_name: "edge_ransomware"
description: "Best origlike regime: FedAvg + SmolLM-135M + LoRA r=32, LR=3e-4, frac=0.2, 30 rounds (original scoring)"

# --- Paths ---
data_base_path: "./data/ids_ransomware/"
results_path: "./results/"

# --- Data Processing Settings ---
session_window_spliter: " ;-; "
force_reprocess_data: false
benign_train_fraction: 0.8

# --- Model Settings ---
model_name: "HuggingFaceTB/SmolLM-135M"
lora: True
lora_rank: 32
lora_alpha_multiplier: 4
lora_dropout: 0.1

# --- Federated Learning Settings ---
use_parallel_training: true
num_rounds: 30
num_clients: 50
client_frac: 0.2

data_distribution_strategy: "hetero_device"
non_iid_alpha: 0.5

client_selection_strategy: "data_size_proportional"
use_weighted_aggregation: true

fedprox_mu: 0.0

# --- Client Training Settings ---
max_steps: 50
batch_size: 4
gradient_accumulation_steps: 16
initial_lr: 0.0003
min_lr: 0.00001
lr_scheduler_type: 'cosine'

# --- Evaluation Settings ---
top_k_values: [1, 3, 5, 10]
f1_threshold_steps: 1000
enable_temporal_metrics: false

threshold_selection: "f1_max"

evaluator_version: "new"
accuracy_method: "original"

