# Evaluation-only (operational): fpr_target + temporal metrics
#
# Purpose:
#   Re-evaluate an existing trained run stored under `results/final/FINAL_LoRA16_FedProx_0005_Orig_R30`
#   without retraining, producing:
#     - f1_scores_fpr_target.csv
#     - temporal_metrics_fpr_target.csv
#
# Run with:
#   ./.venv/bin/python scripts/evaluate_only.py --config configs/final/eval_operational_final_mu0005_r30.yaml

simulation_name: "FINAL_LoRA16_FedProx_0005_Orig_R30"
dataset_name: "edge_ransomware"
description: "Eval-only operational: fpr_target=0.01 + temporal metrics (flow) for FINAL_LoRA16_FedProx_0005_Orig_R30"

data_base_path: "./data/ids_ransomware/"
results_path: "./results/final/"

session_window_spliter: " ;-; "
force_reprocess_data: false
benign_train_fraction: 0.8
content_mode: "raw"

model_name: "HuggingFaceTB/SmolLM-135M"
lora: True
lora_rank: 16
lora_alpha_multiplier: 4
lora_dropout: 0.1

# Evaluator settings
top_k_values: [1, 3, 5, 10]
f1_threshold_steps: 1000

# Operational thresholding
threshold_selection: "fpr_target"
fpr_target: 0.01
calibration_source: "train_benign"
calibration_num_samples: 2000

# Temporal / deployment-oriented metrics (TTD / coverage / benign FPR)
enable_temporal_metrics: true
temporal_eval_mode: "flow"
temporal_window_seconds: 30
temporal_window_agg: "mean"

# Match the paper's "origlike" scoring regime
evaluator_version: "new"
accuracy_method: "original"

