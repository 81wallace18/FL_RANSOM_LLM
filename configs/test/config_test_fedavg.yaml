# configs/test/config_test_fedavg.yaml
# Phase 1: Smoke test - FedAvg baseline (~20-30 min)

# --- General Experiment Settings ---
simulation_name: "TEST_FedAvg_Phase1_R15"
dataset_name: "edge_ransomware"
description: "Phase 1 smoke test: FedAvg baseline (15 rounds, fast-ish)"

# --- Paths ---
data_base_path: "./data/ids_ransomware/"
results_path: "./results/"

# --- Data Processing Settings ---
session_window_spliter: " ;-; "
force_reprocess_data: True
benign_train_fraction: 0.8

# --- Model Settings ---
model_name: "HuggingFaceTB/SmolLM-135M"
lora: True
lora_rank: 16
lora_alpha_multiplier: 2
lora_dropout: 0.1

# --- Federated Learning Settings ---
use_parallel_training: false   # 1 GPU
num_rounds: 15                 # Phase 1: 15 rounds (ainda rápido; já mostra tendência)
num_clients: 10                # Reduced for speed
# Para ficar mais próximo do cenário do relatório (mais clientes por rodada),
# usamos uma fração maior aqui: 0.5 => 5 clientes por rodada.
client_frac: 0.5

# Data distribution (Non-IID - same as FedProx test)
data_distribution_strategy: "hetero_device"
non_iid_alpha: 0.5

# Client selection and aggregation
client_selection_strategy: "data_size_proportional"
use_weighted_aggregation: true

# FedProx DISABLED (baseline)
fedprox_mu: 0.0

# --- Client Training Settings ---
max_steps: 10                  # Reduced for Phase 1
batch_size: 8
gradient_accumulation_steps: 8 # Reduced for speed
# Relatório: sweet-spot em Non-IID (evita estagnação de 1e-4 sem colapsar 5e-4)
initial_lr: 0.0003
min_lr: 0.00001
lr_scheduler_type: 'cosine'

# --- Evaluation Settings ---
top_k_values: [1, 3, 5, 10]
f1_threshold_steps: 500
enable_temporal_metrics: false

# Threshold
threshold_selection: "f1_max"

# Evaluation behavior
evaluator_version: "new"
accuracy_method: "shifted"
