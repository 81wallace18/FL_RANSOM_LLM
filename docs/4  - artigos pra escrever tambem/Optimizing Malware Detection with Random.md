## Optimizing Malware Detection with Random

## Forest, XGBoost, LightGBM, and LLM-Reporting

1 st  Aticha Charoenthanakitkul Data Science and Innovation Program College of Interdisciplinary Studies, Thammasat University. Pathum Thani, Thailand. aticha.char@dome.tu.ac.th

2 nd  Pranodnard Viboonsang Data Science and Innovation Program College of Interdisciplinary Studies, Thammasat University. Pathum Thani, Thailand. pranodnard.vi@dome.tu.ac.th

Abstract -This study presents a comprehensive framework for  malware  detection  that  integrates  traditional  machine learning  algorithms  with  advanced  large  language  models (LLMs) to enhance both classification accuracy and automated report  generation.  The  proposed  approach  leverages  three widely used machine learning models -Random Forest, XGBoost, and  LightGBM -to classify different types of malwares based on extracted features from the EMBER dataset, a well-known benchmark dataset for malware analysis. Each of these  models  was  trained  and  evaluated  to  determine  their effectiveness in identifying malicious software with high accuracy.  Among the  tested  algorithms,  LightGBM  exhibited the  best  performance,  achieving  an  impressive  classification accuracy  of  83%.  XGBoost  followed  closely  with  81%,  while Random  Forest  achieved  an  accuracy  of  79%.  To  further enhance the usability of the system for cybersecurity analysts, the  study  incorporates  a  large  language  model,  specifically LLaMA, which is accessed via an API. This model is employed to  generate  detailed,  human-readable  reports  that  provide insights  into  detected  malware  threats.  By  automating  the reporting  process,  the  framework  aims  to  reduce  the  manual effort required for malware analysis, allowing security professionals to focus on high-priority threats. Future research will  focus  on  improving  classification  performance  through advanced  feature  engineering  techniques  and  exploring  deep learning-based neural network architectures to further enhance the accuracy and efficiency of malware detection and analysis.

Keywords -Malware  Detection,  Random  Forest,  XGBoost, LightGBM, LLM, Cybersecurity

## I. INTRODUCTION

Malware has evolved in sophistication, making it crucial to  develop  effective  classification  methods  to  identify  and mitigate various types of threats [5]. The increasing complexity and adaptability of modern malware pose significant challenges to cybersecurity professionals, necessitating the continuous improvement of detection techniques. Traditional detection systems, such as signaturebased and heuristic-based approaches, often fail to identify new malware strains due to their rapidly changing nature [6]. These  methods  rely  heavily  on  predefined  patterns  and known attack behaviors, which frequently circumvent through obfuscation, polymorphism, and metamorphism.

Machine  learning  approaches  have  shown  significant potential  in  improving  classification  accuracy,  especially when  handling large and diverse datasets [7]. Unlike traditional  detection  techniques,  machine  learning  models can  adapt  to  new  threats  by  learning  from  patterns  and anomalies  in  historical  data.  By  leveraging supervised  and

3 rd  Somkiat Kosolsombat Data Science and Innovation Program College of Interdisciplinary Studies, Thammasat University. Pathum Thani, Thailand. somkiatk@tu.ac.th

unsupervised learning techniques, these models can effectively differentiate between benign and malicious software,  providing  a  more  proactive  defense  mechanism against  cyber threats. Moreover, deep learning architecture such as convolutional neural networks (CNNs) and recurrent neural networks  (RNNs) have demonstrated promising results in feature extraction and classification tasks.

This study leverages machine learning models -Random Forest, XGBoost, and LightGBM -for classifying different types of  malwares  [8].  These  ensemble-based  learning techniques  have  been  widely  used  due  to  their  ability  to handle high-dimensional data, robustness against noise, and superior  performance  in  classification  tasks.  Additionally, feature  engineering  techniques  such  as  Term  FrequencyInverse Document Frequency (TF-IDF) and Principal Component Analysis (PCA) are employed to enhance model performance.

In addition, LLaMA, a large language model, is integrated into  the  framework  via  an  API  to  automatically  generate reports on classification outcomes [9]. This integration aims to assist  analysts by providing a clear understanding of the detection results, thus enhancing decision-making and response  times  [10].  By  summarizing  findings,  identifying potential attack vectors, and suggesting mitigation strategies, LLaMA facilitates a more efficient and informed approach to cybersecurity incident response. This combination of machine  learning-driven classification and AI-generated reporting  represents  a  significant  step  forward  in  modern malware detection and mitigation strategies.

## II. LITERATURE REVIEW

Several  studies  have  explored  various  approaches  to malware  detection  and  classification.  Traditional  malware detection  methods  rely  on  signature-based  and  heuristicbased techniques, which struggle to detect newly emerging malware variants [1]. To address these challenges, researchers have increasingly turned to machine learning and deep learning-based solutions [4]. Supervised learning models such as decision trees, support vector machines, and ensemble learning techniques like Random Forest, XGBoost, and  LightGBM  have  demonstrated  promising  results  in detecting and classifying malware [5][13].

The use of deep learning models has also gained traction, with  architectures  such  as  convolutional  neural  networks (CNNs)  and  long  short-term  memory  (LSTM)  networks

being  applied  to  analyze  malware  behavior  and  binary executables [4][8]. These methods leverage feature extraction and anomaly detection to enhance classification accuracy.

Furthermore, large language models (LLMs) have recently been  integrated  into  cybersecurity  frameworks  to  assist  in malware  analysis  and  automated  reporting.  Studies  have demonstrated that LLMs can generate interpretable reports, improve  code  comprehension,  and  facilitate  cybersecurity incident response [6][7]. The application of transfer learning in LLMs has further enhanced malware detection accuracy by leveraging system calls and behavioral analysis [11].

Additionally,  researchers  have  explored  generative  AI models in cybersecurity, particularly in detecting and countering  adversarial  attacks  on  machine  learning  models [6][15]. A comprehensive review of LLM applications and vulnerabilities in cybersecurity emphasizes the importance of explainability and robustness in AI-driven malware detection frameworks [12].

Future  research  will  focus  on  enhancing  classification capabilities through the integration of deep learning models such as CNNs and transformers [17]. These advanced models have shown promise in identifying complex patterns within malware  behavior  and  could  further improve  detection accuracy. Additionally, optimizing feature engineering techniques  by  leveraging  automated  feature  selection  and dimensionality reduction methods will be explored to refine classification  performance  [14].  By  continuously  evolving the framework, this study aims to contribute to the development of more robust and intelligent malware detection  systems  that  can  effectively  adapt  to  emerging cyber threats [18].

## III. METHODOLOGY

The dataset used in this study is the EMBER dataset, which contains  labeled  samples  representing  different  malware types [11]. The workflow involves several steps:

## A. Data Collection and Preprocessing

- Dataset: The EMBER dataset was used, which consists of a diverse set of labeled samples of both malware and benign files. This dataset is widely used for malware research  due  to  its  comprehensive  set  of  features, including metadata, API calls, and byte-level characteristics.
- Data Conversion: The original dataset was provided in JSON  format,  which  is  highly  versatile but less convenient for large-scale data analysis. All JSON files were converted to CSV format to facilitate easier data manipulation  and  integration  with  machine  learning libraries [12]
- Feature Extraction: Key features extracted include:
1. Byte Histograms: These represent the byte distributions within executable files, which can help distinguish between different types of malwares and benign software.
2. Function Imports: The functions imported by executable  files  provide  insights  into  the  intended

behavior of the software, which can indicate malicious intent.

3. File  Size  and  Metadata:  Other  Metadata  features, such as file size and headers, were also used, as they can provide crucial clues to classify malware effectively.
- Data Cleaning: Inconsistencies and missing values in the dataset were addressed by imputing values based on the dataset mean or mode, as appropriate. This ensured that  the  models  received  clean  data  for  training  and testing, minimizing noise [13].
- Data Splitting: The data was split into training and test sets,  with  80%  of  the  samples  used  for  training  and 20%  for  testing.  Cross-validation  was  employed  to further assess the models' robustness [14].
- B. Machine Learning Models for Classification
- Model Selection: Three machine learning models were selected for malware classification:
1. Random Forest: An ensemble learning method based on decision trees, which works well with categorical and continuous features [15].
2. XGBoost:  A  gradient  boosting  algorithm  that  has shown significant success in handling structured/tabular data [16].
3. LightGBM: A gradient boosting framework that is particularly  fast  and  efficient,  especially  for  large datasets with many features [17].
- Training Process:
1. Hyperparameter Tuning: Each model was optimized through hyperparameter tuning using a grid search approach. Parameters like the number of estimators, learning rate, and depth were tuned for each model to achieve optimal performance.
2. Feature  Importance:  The  importance  of  individual features was assessed to understand which features had  the  most  influence  on  classification  accuracy. For instance, byte histograms and specific function imports  ranked  among  the  top  features  across  all models.
- Evaluation Metrics: The models were evaluated based on several metrics:
1. Accuracy:  Measures  the  percentage  of  correctly classified samples.
2. Precision:  Indicates  how  many  of  the  predicted malware were truly malware.
3. Recall:  Shows  how  many actual malware  samples were correctly identified.
4. F1-Score: Provides a balance between precision and recall.

## C. LLM-Driven Report Generation

- Once the classification was complete, a large language model  (LLM),  specifically  LLaMA,  was  utilized  to generate comprehensive reports for each classification. The LLM was accessed via an API, which allowed for seamless integration into the malware detection

workflow. The LLM provided a detailed summary of classification results, feature importances, and general model performance, simplifying the work of cybersecurity analysts [18].

## IV. RESULTS

The models were evaluated on the test dataset to determine their  ability  to  classify  malware  accurately.  Below  is  a detailed  summary  of  the  evaluation  metrics  and  a  visual representation of the performance.

TABLE I. Performance Comparison of Machine Learning Models

| Metric    | Random Forest   | XGBoost   | LightGBM   |
|-----------|-----------------|-----------|------------|
| Accuracy  | 79%             | 81%       | 83%        |
| Precision | 78%             | 80%       | 82%        |
| Recall    | 80%             | 82%       | 84%        |
| F1-Score  | 79%             | 81%       | 83%        |

## · Model Analysis

1. LightGBM emerged as the top-performing model, achieving  an  accuracy  of  83%,  due  to  its  efficient handling of high-dimensional data and feature interactions.
2. XGBoost performed slightly lower, with an accuracy of 81%. Its robust boosting technique made it  a  strong  competitor,  although  it  required  more computational resources compared to LightGBM.
3. Random  Forest showed  good  performance but lagged behind LightGBM and XGBoost. Its reliance on ensemble decision trees provided robust results but was less effective in capturing complex feature interactions.
- LLM  Reporting  The  LLaMA  model  was  used  to automatically generate reports after classification. These reports included key findings, feature importances,  and  recommendations  for  next  steps, which  were  made  accessible  through  the  API.  The generated reports helped provide a deeper understanding of the malware threat landscape, aiding cybersecurity analysts in their response strategies.
- Data Conversion Impact The conversion of data from JSON  to  CSV  format  significantly  improved  the efficiency  of  data  processing.  CSV  format  is  better suited for tabular data analysis and is directly compatible with pandas, which allowed for faster data manipulation and made the preprocessing steps more straightforward.

<!-- image -->

This bar chart illustrates the accuracy of the three machine learning models -Random Forest, XGBoost, and LightGBM -used  for  classifying  malware.  Each  model  is represented by a bar with different colors for easy comparison. The accuracy metric reflects the percentage of malware  samples  that  were  correctly  classified  by  each model.

The LightGBM model exhibited the highest classification accuracy,  reaching  83%,  followed  closely  by  XGBoost  at 81%, and Random Forest at 79%. These results indicate that the boosting techniques employed by XGBoost and LightGBM  provide  a  notable  improvement  over  Random Forest, which relies on a bagging approach [19].

The superior performance of LightGBM can be attributed to  its  efficiency  in  handling  high-dimensional  data  and  its ability  to  capture  complex  feature  interactions  effectively. XGBoost  also  showed  competitive  results,  suggesting  that gradient  boosting  methods  are  well-suited  for  this  type  of malware  detection  problem  [20].  In  comparison,  Random Forest, while still achieving relatively high accuracy, lagged behind the other two models, highlighting the limitations of bagging in capturing intricate patterns in malware datasets.

Overall, the findings demonstrate that LightGBM is the most effective model for malware classification among the three tested, due to its combination of speed, accuracy, and ability  to  handle  diverse  features.  The  results  highlight  the importance of selecting appropriate machine learning techniques  for  malware  classification  to  enhance  accuracy and, consequently, overall cybersecurity defenses.

## V. DISCUSSION

The  integration  of  LLaMA  for  generating  automated reports provides a significant advantage in terms of interpretability  and  efficiency.  The  LLM-generated  reports summarize  the  model  outputs  in  a  way  that  is easily understandable by analysts, thus facilitating a more effective response to detected threats.

The accuracy scores indicate that LightGBM is particularly well-suited for this task, likely due to its ability to manage complex feature interactions. A key limitation of this study was the dataset size and computational resources, which restricted further exploration of deep learning models. Future work will consider optimizing features and expanding the  dataset,  as  well  as  investigating  neural  networks  like convolutional  neural  networks  (CNNs)  for  more  nuanced classifications. While this study focuses on classical machine learning  algorithms,  it  is  important  to  highlight  how  deep learning  methods,  such  as  Convolutional  Neural  Networks (CNNs) and Recurrent Neural Networks (RNNs), compare. CNNs  have  demonstrated  high  performance  in  malware detection when malware binaries are converted into grayscale images. RNNs, on the other hand, are effective for sequential data like API call traces. However, these models often require substantial  computational  resources,  longer  training  times, and large labeled datasets. In contrast, tree-based models like LightGBM, XGBoost, and Random Forest offer interpretable results, are easier to deploy, and are well-suited for structured data like the EMBER dataset, making them more practical in environments  with  limited  resources  or  urgent  deployment requirements.

Adversarial  Threats  and  Mitigation  Machine  learning models for malware detection are susceptible to adversarial attacks, where attackers intentionally modify input features to  trick  the  model  into  misclassifying  malware  as  benign. These  subtle  modifications,  often  undetectable  to  humans, can  severely  degrade  model  performance.  For  instance, attackers might inject harmless-looking code snippets or API calls  to  bypass  detection.  To  address  this,  future  research should explore adversarial training techniques, which expose models  to  manipulated  inputs  during  training,  improving resilience. Additionally, explainable AI (XAI) tools can help identify  suspicious  predictions,  while  combining  static  and behavioral features could further strengthen detection systems.

## VI. CONCLUSION

This paper presented a framework for malware classification using Random Forest, XGBoost, and LightGBM, combined with automated reporting using LLaMA via an API. The experimental results demonstrated that LightGBM achieved the highest classification performance,  outperforming  the  other  models  in  terms  of accuracy,  precision,  and  recall.  This  superior  performance can be attributed to LightGBM's ability to efficiently handle large datasets and its advanced boosting mechanism, which optimizes model training and prediction speed. The integration  of  LLaMA  further  enhanced  the  framework  by generating detailed and interpretable reports, allowing security analysts to quickly assess classification results and make informed decisions.

Future  research  will  focus  on  enhancing  classification capabilities through the integration of deep learning models such as convolutional neural networks (CNNs) and transformers. These advanced models have shown promise in identifying  complex  patterns  within  malware  behavior  and could  further improve  detection  accuracy.  Additionally, optimizing  feature  engineering  techniques  by  leveraging automated  feature  selection  and  dimensionality  reduction methods will be explored to refine classification performance. By continuously evolving the framework, this study aims to contribute to the development of more robust and intelligent malware detection systems that can effectively adapt to emerging cyber threats. Moreover, future work will also explore the robustness of the models against adversarial attacks, which pose significant risks in real-world deployments. Ensuring security through adversarial training and  model  interpretability will help maintain  detection accuracy even in the presence of evasion techniques. Additionally, analyzing the trade-offs between model performance  and  computational  efficiency  will  guide  the selection of optimal models for different operational environments.

## REFERENCES

- [1] Gavrilu ţ , D., Cimpoeşu, M., Anton, D. &amp; Ciortuz, L. (2009). Malware Detection Using Machine Learning. https://doi.org/10.1109/IMCSIT.2009.5352759
- [2] Yao,  Y.,  et  al.  (2024).  A  survey  on  large  language  model  (LLM) security and privacy: The Good, The Bad, and The Ugly. https://doi.org/10.1016/j.hcc.2024.100211
- [3] Zahan, N., et al. (2024). Leveraging Large Language Models to Detect npm Malicious Packages. https://doi.org/10.48550/arXiv.2403.12196
- [4] Bensaoud, A., Kalita, J., &amp; Bensaoud, M. (2024). A survey of malware detection using deep learning. https://doi.org/10.1016/j.mlwa.2024.100546
- [5] Akhtar, M. S.,  &amp; Feng, T. (2023).  Evaluation of Machine Learning Algorithms for Malware Detection. https://doi.org/10.3390/s23020946
- [6] Ferrag,  M.  A.,  et  al.  (2024). Generative  AI  in  Cybersecurity:  A Comprehensive  Review  of  LLM  Applications  and  Vulnerabilities. https://doi.org/10.48550/arXiv.2405.12750
- [7] Ali,  T.,  &amp;  Kostakos,  P.  (2023).  HuntGPT:  Integrating  Machine Learning-Based  Anomaly  Detection and Explainable  AI  with Large Language Models (LLMs). https://doi.org/10.48550/arXiv.2309.16021
- [8] Faruk, M. J. H., et al. (2021). Malware Detection and Prevention using Artificial Intelligence Techniques. https://doi.org/10.1109/BigData52589.2021.9671434
- [9] Williamson,  A.  Q.,  &amp;  Beauparlant,  M.  (2024).  Malware  Reverse Engineering with Large Language Model for Superior Code Comprehensibility and IoC Recommendations. unpublished.
- [10] Zhao,  W.,  Wu,  J.,  &amp;  Meng,  Z.  (2024).  AppPoet:  Large  Language Model  based  Android  Malware  Detection  via  Multi-View  Prompt Engineering. https://doi.org/10.48550/arXiv.2404.18816
- [11] Sánchez,  S.  P.  M.,  Celdrán,  A.  H.,  Bovet,  G.,  &amp;  Pérez,  M.  (2024). Transfer Learning in Pre-Trained Large Language Models for Malware Detection Based on System Calls. http://dx.doi.org/10.48550/arXiv.2405.09318
- [12] Xu, H., et al. (2024). Large Language Models for Cyber Security: A Systematic Literature Review. https://doi.org/10.48550/arXiv.2405.04760
- [13] Azeem,  M.,  Khan,  D.,  Iftikhar,  S.,  Bawazeer,  S.,  &amp;  Alzahrani,  M. (2024). Analyzing  and  comparing  the  effectiveness  of  malware detection: A study of machine learning approaches. https://doi.org/10.1016/j.heliyon.2023.e23574
- [14] Zada, I. (2024). Fine-Tuning Cyber Security Defenses: Evaluating Supervised Machine Learning Classifiers for Windows Malware Detection. https://doi.org/10.32604/cmc.2024.052835
- [15] Motlagh, F. N., et al. (2024). Large Language Models in Cybersecurity: State-of-the-Art. https://doi.org/10.48550/arXiv.2402.00891
- [16] Al-Karaki, J., Khan, M. A., &amp; Omar, M. (2024). Exploring LLMs for Malware Detection: Review, Framework Design, and Countermeasure Approaches. https://doi.org/10.48550/arXiv.2409.07587

- [17] Toluwase, Micheal, &amp; Rajesh. (2024). Enhancing Cyber Threat Detection with an Improved Artificial Neural Network Model https://doi.org/10.1016/j.dsm.2024.05.002
- [18] Huang, L., &amp; Zhang, Y. (2023). Large-Scale Malware Analysis with Explainable AI. https://doi.org/10.48550/arXiv.2309.07587 Ashley Q. Williamson, &amp;Michael Beauparlant (2024). Malware Reverse Engineering with Large Language Model for Superior Code Comprehensibility and IoC Recommendations https://doi.org/10.21203/rs.3.rs-4471373/v1
- [19] Chen, T., &amp; Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 785 -794. https://doi.org/10.1145/2939672.2939785