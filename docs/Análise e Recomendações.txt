 Análise e Recomendações para Melhorar a Acurácia

  Baseado na análise do seu projeto e pesquisa de técnicas recentes, aqui estão as principais recomendações organizadas por área:

  ---
  1. Melhorias no LoRA (Mais Impacto Imediato)

  | Técnica       | Status Atual | Recomendação                                           |
  |---------------|--------------|--------------------------------------------------------|
  | Rank          | 8            | Aumentar para 16 ou 32                                 |
  | Alpha         | rank * 2     | Manter (já está correto)                               |
  | Target Layers | Verificar    | Aplicar em todas as camadas lineares, não só attention |
  | Epochs/Steps  | 10 steps     | Aumentar para 30-50 steps                              |

  Nova alternativa interessante: https://towardsdatascience.com/are-you-still-using-lora-to-fine-tune-your-llm/ - técnicas baseadas em SVD que mostram melhor performance em datasets específicos com menos parâmetros.

  ---
  2. Substituir FedAvg por Algoritmos Mais Robustos

  Seu projeto usa FedAvg, que sofre com dados Non-IID. Alternativas mais eficazes:

  | Algoritmo                                                    | Vantagem                                            | Complexidade |
  |--------------------------------------------------------------|-----------------------------------------------------|--------------|
  | https://en.wikipedia.org/wiki/Federated_learning             | Adiciona termo proximal que reduz client drift      | Baixa        |
  | https://pmc.ncbi.nlm.nih.gov/articles/PMC11523028/           | Regularização dinâmica, agnóstico à heterogeneidade | Média        |
  | https://link.springer.com/article/10.1007/s10922-023-09782-9 | Agrupa clientes similares, ensemble learning        | Média        |
  | https://arxiv.org/html/2305.10730                            | Recombina modelos ao invés de agregar               | Alta         |

  Recomendação prioritária: Implementar FedProx - é a modificação mais simples:

  # Adicionar ao loss do cliente:
  proximal_term = (mu / 2) * sum((w_local - w_global)^2)
  total_loss = task_loss + proximal_term

  ---
  3. Two-Stage Hybrid Framework

  Uma técnica que mostrou 99.14% de acurácia em detecção de anomalias IoT:

  1. Primeiro estágio: Seu modelo generativo (SmolLM) treinado em tráfego benigno
  2. Segundo estágio: Classificador adicional (Histogram-based Gradient Boosting ou XGBoost) usando features extraídas

  Referência: https://www.mdpi.com/2624-831X/6/3/48

  ---
  4. Melhorias no Threshold Selection

  Sua implementação atual usa F1-Max ou FPR-Target. Uma técnica mais robusta:

  https://www.nature.com/articles/s41598-024-76961-2: Agrega estatísticas (média, desvio padrão, quantis) dos scores de anomalia de todos os clientes para calcular um threshold global mais robusto, especialmente em cenários Non-IID.

  ---
  5. Server Learning Auxiliar

  Adicionar dados auxiliares no servidor (mesmo que pequeno) melhora significativamente a convergência:

  "Auxiliary server learning can achieve significant improvements in both model accuracy and convergence time even when the dataset utilized by the server is small." - https://pmc.ncbi.nlm.nih.gov/articles/PMC11523028/

  ---
  Plano de Implementação Sugerido (por ordem de impacto/esforço):

  1. Fácil - Aumentar lora_rank para 16-32 e verificar target_modules
  2. Fácil - Aumentar max_steps para 30-50
  3. Médio - Implementar FedProx (adicionar termo proximal)
  4. Médio - Melhorar threshold calculation com summary statistics
  5. Avançado - Adicionar segundo estágio com classificador tradicional

  Quer que eu implemente alguma dessas técnicas no seu código?

  ---
  Sources:
  - https://magazine.sebastianraschka.com/p/practical-tips-for-finetuning-llms
  - https://www.databricks.com/blog/efficient-fine-tuning-lora-guide-llms
  - https://www.nature.com/articles/s41598-024-76961-2
  - https://link.springer.com/article/10.1007/s10922-023-09782-9
  - https://www.mdpi.com/2624-831X/6/3/48
  - https://pmc.ncbi.nlm.nih.gov/articles/PMC11523028/
  - https://arxiv.org/html/2305.10730

- Federated Benign‑Only Ransomware Detection on IoT/Edge Network Flows with LoRA‑Tuned Small Language Models

  Alternativas (mais curtas):

  - Privacy‑Preserving Ransomware Detection at the Edge via Federated LoRA Fine‑Tuning of Small Language Models
  - Toward Deployable Ransomware Detection in IoT/Edge: Federated Benign‑Only Language Modeling on Network Flows


 Para a versão final, você provavelmente ainda vai precisar adicionar (mesmo que não sejam “related work”) pelo menos:

  - FedAvg / Federated Learning (McMahan et al., 2017)
  - LoRA (Hu et al., 2021)
  - Edge-IIoTSet dataset paper (Ferrag et al., 2022 — dataset, não o SecurityBERT)
  - SmolLM (se você citar a família/modelo com referência formal)


Resumo das Implementações

  1. FedProx (src/federated_learning/client.py)

  - Classe FedProxTrainer com termo proximal no loss
  - Ativado via fedprox_mu > 0 no config

  2. Configurações Atualizadas

  | Arquivo                          | FedProx           |
  |----------------------------------|-------------------|
  | config_edge_ransomware.yaml      | mu=0.01 (ativo)   |
  | config_edge_fedavg_baseline.yaml | mu=0.0 (baseline) |
  | config.yaml                      | mu=0.0            |
  | config_hdfs.yaml                 | mu=0.0            |

  3. CSVs com Colunas FedProx

  Todos os CSVs agora incluem fedprox_mu e aggregation_method:
  - f1_scores.csv
  - f1_scores_antigo.csv
  - temporal_metrics.csv
  - communication_metrics.csv
  - inference_benchmark.csv

  4. Script de Plotting (scripts/plot_results.py)

  Uso:
  # Auto-detecta experimentos
  python scripts/plot_results.py --results_dir results/

  # Ou especifica experimentos
  python scripts/plot_results.py \
      --fedavg results/EdgeRansomware_SmolLM135M_FedAvg_Baseline \
      --fedprox results/EdgeRansomware_SmolLM135M_FedProx \
      --output_dir img/

  Gráficos gerados:
  | Arquivo                | Descrição                   |
  |------------------------|-----------------------------|
  | f1_convergence.png     | Curva F1 por rodada         |
  | metrics_comparison.png | Barras F1/Precision/Recall  |
  | convergence_speed.png  | Rodadas para atingir F1≥0.8 |
  | f1_by_topk.png         | F1 para cada Top-K          |
  | communication_cost.png | Custo comunicação acumulado |
  | temporal_metrics.png   | TTD e Coverage              |
  | results_table.tex      | Tabela LaTeX para artigo    |

  ---
  Para Rodar os Experimentos
 python main.py --config configs/test/config_test_fedavg.yaml && \
  python main.py --config configs/test/config_test_fedprox.yaml && \
  python scripts/plot_results.py \
      --fedavg results/TEST_FedAvg_Phase1 \
      --fedprox results/TEST_FedProx_Phase1 \
      --output_dir img/test/



 Você não vai precisar reescrever “muita coisa”, mas precisa alinhar 3 pontos do texto com o que o código/config agora fazem com
  FedProx.

  1) O que o código realmente faz agora (FedProx)

  - FedProx foi implementado como termo proximal na perda do cliente (não é um novo agregador no servidor): src/federated_learning/
    client.py:16–src/federated_learning/client.py:52.
  - Ele penaliza o desvio do modelo local em relação ao global apenas nos parâmetros treináveis (requires_grad). Como você usa LoRA, na
    prática isso vira “FedProx sobre os adapters LoRA”.
  - O servidor continua agregando por média (FedAvg/weighted FedAvg). Então no paper evite escrever “FedProx aggregation”; o correto é
    “FedProx (proximal regularization) with FedAvg-style aggregation”.

  2) Onde o texto precisa mudar (pouco, mas em lugares certos)

  - Seção 3.3 (Metodologia/treino): adicionar 1 parágrafo descrevendo FedProx e a fórmula
    (L = L_{\text{LM}} + \frac{\mu}{2}\lVert \theta - \theta^{(t)} \rVert^2),
    deixando explícito que (\theta) são os parâmetros treináveis (LoRA) e que (\mu=0) recupera FedAvg.
  - Seção 4 (Setup): atualizar hiperparâmetros conforme o config atual e incluir FedProx:
      - Seu configs/config_edge_ransomware.yaml:19 mostra lora_rank: 16 (não 32 como estava antes na nossa tabela).
      - configs/config_edge_ransomware.yaml:42 mostra fedprox_mu: 0.01.
      - configs/config_edge_ransomware.yaml:46 mostra max_steps: 50 (antes escrevemos 75).
      - Também citar que existe baseline “igual, mas mu=0”: configs/config_edge_fedavg_baseline.yaml:39.
  - Seção 5 (Resultados/Discussão): no RQ3, incluir explicitamente o eixo FedAvg (μ=0) vs FedProx (μ>0) sob Non‑IID, e nas tabelas
    colocar uma coluna mu/“method”.

  3) Referência (bibliografia)
  Se você vai mencionar FedProx no método/experimentos, tem que citar o paper do FedProx (arXiv:1812.06127). Não precisa entrar no
  Related Work; pode citar na Seção 3/4.

  Observação rápida de código (não é escrita, mas pode te travar)

  - Em src/federated_learning/client.py:86 você usa dtype=torch.float16 no from_pretrained; em várias versões do Transformers o
    parâmetro correto é torch_dtype. Se seu ambiente reclamar, precisa ajustar.

  Se quiser, eu já reescrevo os trechos específicos das Seções 3.3 e 4 (e a tabela do setup) incorporando FedProx e atualizando os
  valores para bater 1:1 com configs/config_edge_ransomware.yaml.

  Locais do paper que precisam de atenção (pra ficar 100% consistente)

  1. Seção 3 (Metodologia / Treino LM)
      - Agora você pode afirmar corretamente: dynamic padding e loss masking via attention_mask.
      - Referencie que o score é top‑k de next-token (porque accuracy_method=shifted).
  2. Seção 4 (Dataset/Split/Setup)
      - Atualizar a descrição do split: treino benign-only; teste contém todo o ransomware.
      - Atualizar as contagens (elas vão mudar quando você reprocessar).
  3. Seção 5 (Métricas temporais / Discussão) — muito importante
      - O subset tem um problema estrutural: ransomware está concentrado em um único Src IP e não há benigno desse host. Então
        coverage/TTD “por dispositivo” ficam com N=1 (coverage vira 0/1). Isso tem que aparecer como limitação/ameaça à validade (e
        moderar o claim).
  4. Threats to validity / Limitations
      - Explicitar: ataque vindo de um único host/par (Src/Dst), possível efeito de “host/domain shift”, mesmo sem IP no Content.


